{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from datetime import datetime\n",
    "from os import getcwd\n",
    "from os.path import join\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "\n",
    "from sys import path\n",
    "path.append( join( join( getcwd() , 'functions/' ) ) )\n",
    "\n",
    "from functions import preprocessing, modelling, postprocessing\n",
    "from config import ConfigDict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigDict.read('config/config_param.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'params': {'input_data': {'5_labels': 'data/SA_4_Categories.csv'},\n",
       "  'tokenization_options': {'sent_tokenizer': False,\n",
       "   'use_nltk_cleaning': False,\n",
       "   'text_cleaning': True,\n",
       "   'use_tfidf_tokenizer': False,\n",
       "   'use_keras_tokenizer': True,\n",
       "   'use_pretrained_embeddings': True,\n",
       "   'use_glove_pretrained_embeddings_weights': False,\n",
       "   'use_tfidf_as_embedding_weights': True},\n",
       "  'data': {'epochs': 30,\n",
       "   'batch_size': 16,\n",
       "   'num_words': 5000,\n",
       "   'cv': 4,\n",
       "   'n_iter': 5,\n",
       "   'seq_input_len': 40,\n",
       "   'embedding_dim': 40,\n",
       "   'nodes_hidden_dense_layer': 5,\n",
       "   'filepath': 'D:/Semillero Data Science/Deep Learning/pre-trained Word Embeddings/GloVe/glove.6B.50d.txt'},\n",
       "  'hyperparam': {'num_filters_cv': [[64, 16], [64, 32], [128, 16], [128, 32], [256, 64], [256, 32], [256, 64], [512, 128], [512, 32]],\n",
       "   'kernel_size_cv': [[2, 3], [2, 4], [3, 4], [3, 5]],\n",
       "   'vocab_size': [3000, 4000, 5000, 6000],\n",
       "   'embedding_dim': [20, 30, 40, 50],\n",
       "   'seq_input_len': [50, 40, 30, 20, 10],\n",
       "   'nodes_hidden_dense_layer': [5, 10, 15, 20, 40],\n",
       "   'use_pretrained_embeddings': [True, False]}}}"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%d-%m-%Y_%H_%M_%S\")\n",
    "\n",
    "sent_tokenizer = config['params']['tokenization_options']['sent_tokenizer'] # TODO: Adjust for input to CNN\n",
    "\n",
    "# Text Cleaning Options\n",
    "use_nltk_cleaning = config['params']['tokenization_options']['use_nltk_cleaning']\n",
    "text_cleaning = config['params']['tokenization_options']['text_cleaning']\n",
    "\n",
    "# Word Tokenizer Options\n",
    "use_tfidf_tokenizer = config['params']['tokenization_options']['use_tfidf_tokenizer'] # TODO: Adjust for input to CNN\n",
    "use_keras_tokenizer = config['params']['tokenization_options']['use_keras_tokenizer']\n",
    "\n",
    "# If set to FALSE then keras embedding space training is used instead\n",
    "# Embedding Space possibilites are GloVe or TFIDF\n",
    "use_pretrained_embeddings = config['params']['tokenization_options']['use_pretrained_embeddings']\n",
    "\n",
    "# Only if use_pretrained_embeddings == True then select embedding vector space type\n",
    "use_glove_pretrained_embeddings_weights = config['params']['tokenization_options']['use_glove_pretrained_embeddings_weights']\n",
    "use_tfidf_as_embedding_weights = config['params']['tokenization_options']['use_tfidf_as_embedding_weights']\n",
    "\n",
    "# Dictionary which will cotain all the model's variables\n",
    "data = {}\n",
    "\n",
    "# Initialize Model\n",
    "data['epochs'] = config['params']['data']['epochs'] # NO. of optimizatoin runs\n",
    "data['batch_size'] = config['params']['data']['batch_size'] # No. of sentences batch to train\n",
    "data['num_words'] = config['params']['data']['num_words'] # No. of words to use in the embedding space of GloVe or TFIDF\n",
    "data['cv'] = config['params']['data']['cv'] # No. of Cross Validations\n",
    "data['n_iter'] = config['params']['data']['n_iter'] # No. of Iterations\n",
    "data['seq_input_len'] = config['params']['data']['seq_input_len'] # Length of the vector sentence ( no. of words per sentence)\n",
    "data['embedding_dim'] = config['params']['data']['embedding_dim'] # Length of the word vector ( dimension in the embedding space)\n",
    "data['nodes_hidden_dense_layer'] = config['params']['data']['nodes_hidden_dense_layer'] # No. of nodes for hidden Dense layer\n",
    "\n",
    "\n",
    "data['filepath'] = config['params']['data']['filepath'] # File path to GLoVe pretrained embedding words\n",
    "data['output_file'] = f\"results/{current_time}_Result.txt\" # Name of output result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'epochs': 30,\n",
       " 'batch_size': 16,\n",
       " 'num_words': 5000,\n",
       " 'cv': 4,\n",
       " 'n_iter': 5,\n",
       " 'seq_input_len': 40,\n",
       " 'embedding_dim': 40,\n",
       " 'nodes_hidden_dense_layer': 5,\n",
       " 'filepath': 'D:/Semillero Data Science/Deep Learning/pre-trained Word Embeddings/GloVe/glove.6B.50d.txt',\n",
       " 'output_file': 'results/05-01-2021_21_42_53_Result.txt'}"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(num_filters_cv = config['params']['hyperparam']['num_filters_cv'], # No of filter to use in convolution\n",
    "                  kernel_size_cv = config['params']['hyperparam']['kernel_size_cv'], # No of words to check per Convolution \n",
    "                  vocab_size = config['params']['hyperparam']['vocab_size'], # Vocab size if keras embedding space training is wanted\n",
    "                  embedding_dim = config['params']['hyperparam']['embedding_dim'], \n",
    "                  seq_input_len = config['params']['hyperparam']['seq_input_len'], \n",
    "                  nodes_hidden_dense_layer = config['params']['hyperparam']['nodes_hidden_dense_layer'],\n",
    "                  use_pretrained_embeddings = config['params']['hyperparam']['use_pretrained_embeddings']\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_time = datetime.now().strftime(\"%d-%m-%Y_%H_%M_%S\")\n",
    "\n",
    "# sent_tokenizer = False # TODO: Adjust for input to CNN\n",
    "\n",
    "# # Text Cleaning Options\n",
    "# use_nltk_cleaning = False\n",
    "# text_cleaning = True\n",
    "\n",
    "# # Word Tokenizer Options\n",
    "# use_tfidf_tokenizer = False # TODO: Adjust for input to CNN\n",
    "# use_keras_tokenizer = True\n",
    "\n",
    "# # If set to FALSE then keras embedding space training is used instead\n",
    "# # Embedding Space possibilites are GloVe or TFIDF\n",
    "# use_pretrained_embeddings = True\n",
    "\n",
    "# # Only if use_pretrained_embeddings == True then select embedding vector space type\n",
    "# use_glove_pretrained_embeddings_weights = True\n",
    "# use_tfidf_as_embedding_weights = False\n",
    "\n",
    "# # Dictionary which will cotain all the model's variables\n",
    "# data = {}\n",
    "\n",
    "# # Initialize Model\n",
    "# data['epochs'] = 30 # NO. of optimizatoin runs\n",
    "# data['batch_size'] = 16 # No. of sentences batch to train\n",
    "# data['num_words'] = 5000 # No. of words to use in the embedding space of GloVe or TFIDF\n",
    "# data['cv'] = 4 # No. of Cross Validations\n",
    "# data['n_iter'] = 5 # No. of Iterations\n",
    "# data['seq_input_len'] = 40 # Length of the vector sentence ( no. of words per sentence)\n",
    "# data['embedding_dim'] = 40 # Length of the word vector ( dimension in the embedding space)\n",
    "# data['nodes_hidden_dense_layer'] = 5 # No. of nodes for hidden Dense layer\n",
    "\n",
    "\n",
    "# data['filepath'] = 'D:/Semillero Data Science/Deep Learning/pre-trained Word Embeddings/GloVe/glove.6B.50d.txt' # File path to GLoVe pretrained embedding words\n",
    "# data['output_file'] = f\"results/{current_time}_Result.txt\" # Name of output result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = dict(num_filters_cv = [(64,16), (64,32), (128,16), (128,32), (256,64), (256,32), (256,64), (512,128), (512, 32)], # No of filter to use in convolution\n",
    "#                   kernel_size_cv = [(2,3), (2,4), (3,4), (3,5)], # No of words to check per Convolution \n",
    "#                   vocab_size = [3000, 4000, 5000, 6000], # Vocab size if keras embedding space training is wanted\n",
    "#                   embedding_dim = [20, 30, 40, 50], \n",
    "#                   seq_input_len = [50, 40, 30, 20, 10], \n",
    "#                   nodes_hidden_dense_layer = [5, 10, 15, 20, 40],\n",
    "#                   use_pretrained_embeddings = [True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Small Test\n",
    "# param_grid = dict(num_filters_cv = [(64,16)],\n",
    "#                   kernel_size_cv = [(2,3)],\n",
    "#                   vocab_size = [5000], \n",
    "#                   embedding_dim = [50],\n",
    "#                   seq_input_len = [50], \n",
    "#                   nodes_hidden_dense_layer = [5],\n",
    "#                   use_pretrained_embeddings = [True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'D:/Data_Science/ClassificationProblems/Sentiment_Analysis/data/SA_4_Categories.csv'\n",
    "corpus = pd.read_csv(data_dir ,encoding='latin-1', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = preprocessing.data_cleaning(corpus = corpus,\n",
    "                       sent_tokenizer = False, \n",
    "                       text_cleaning = True, \n",
    "                       use_nltk_cleaning = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  stable way business life many corporate purcha...      0\n",
       "1  dozens companies already learned supply demand...      0\n",
       "2  capabilities profitable international business...      0\n",
       "3    almost every kind manufacturer answer questions      0\n",
       "4      companies already responded growing pressures      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>stable way business life many corporate purcha...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dozens companies already learned supply demand...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>capabilities profitable international business...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>almost every kind manufacturer answer questions</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>companies already responded growing pressures</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = preprocessing.prepare_training_data(corpus)\n",
    "\n",
    "# Concat two dictionaries\n",
    "data = {**data, **model_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['epochs', 'batch_size', 'num_words', 'cv', 'n_iter', 'seq_input_len', 'embedding_dim', 'nodes_hidden_dense_layer', 'filepath', 'output_file', 'sentences_train', 'sentences_test', 'Y_train', 'Y_test', 'output_label'])"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_keras_tokenizer:\n",
    "    data['X_train'], data['X_test'], data['vocab_size'], data['vocab'] = modelling.keras_tokenizer(num_words = data['num_words'], \n",
    "                                                                                         sentences_train = data['sentences_train'] , \n",
    "                                                                                         sentences_test = data['sentences_test'],\n",
    "                                                                                         seq_input_len = data['seq_input_len'])\n",
    "elif use_tfidf_tokenizer: # Not implemented yet\n",
    "    data['X_train'], data['X_test'], data['vocab_size'], data['vocab'] = modelling.tfidf_tokenizer(num_words = data['num_words'],\n",
    "                                                                                         corpus = corpus,\n",
    "                                                                                         sentences_train = data['sentences_train'],\n",
    "                                                                                         sentences_test = data['sentences_test'])\n",
    "    \n",
    "if use_tfidf_as_embedding_weights:\n",
    "    \n",
    "    data['embedding_matrix'], data['embedding_dim']  = modelling.tfidf_as_embedding_weights(num_words = data['num_words'], \n",
    "                                                                  corpus = corpus, \n",
    "                                                                  sentences_train = data['sentences_train'])\n",
    "    \n",
    "elif use_glove_pretrained_embeddings_weights:\n",
    "    \n",
    "    data['embedding_matrix'], data['embedding_dim'] = modelling.fit_pretrained_embedding_space_glove(embedding_dim = data['embedding_dim'], \n",
    "                                                                           filepath = data['filepath'] , \n",
    "                                                                           vocab = data['vocab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['epochs', 'batch_size', 'num_words', 'cv', 'n_iter', 'seq_input_len', 'embedding_dim', 'nodes_hidden_dense_layer', 'filepath', 'output_file', 'sentences_train', 'sentences_test', 'Y_train', 'Y_test', 'output_label', 'X_train', 'X_test', 'vocab_size', 'vocab', 'embedding_matrix'])"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1206"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "data['embedding_dim'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre = modelling.data_vectorization(sentences_train = data['sentences_train'], \n",
    "                       sentences_test = data['sentences_test'], \n",
    "                       num_words = data['num_words'], \n",
    "                       seq_input_len = data['seq_input_len'], \n",
    "                       filepath = data['filepath'],\n",
    "                       corpus = corpus,\n",
    "                       vocab = data['vocab'],\n",
    "                       embedding_dim = data['embedding_dim'],\n",
    "                       use_keras_tokenizer = use_keras_tokenizer, \n",
    "                       use_tfidf_tokenizer = use_tfidf_tokenizer, \n",
    "                       use_tfidf_as_embedding_weights = use_tfidf_as_embedding_weights,\n",
    "                       use_glove_pretrained_embeddings_weights = use_glove_pretrained_embeddings_weights)\n",
    "\n",
    "# Concat two dictionaries\n",
    "data = {**data, **data_pre}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['epochs', 'batch_size', 'num_words', 'cv', 'n_iter', 'seq_input_len', 'embedding_dim', 'nodes_hidden_dense_layer', 'filepath', 'output_file', 'sentences_train', 'sentences_test', 'Y_train', 'Y_test', 'output_label', 'X_train', 'X_test', 'vocab_size', 'vocab', 'embedding_matrix'])"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid['embedding_matrix'] = ([data['embedding_matrix']])\n",
    "param_grid['output_label'] = [data['output_label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Optimization\n",
    "\n",
    "Reference: https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============\n",
      "embedding_8 (Embedding)      (None, 40, 1206)          4063014   \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 39, 256)           617728    \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 36, 64)            65600     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_8 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 4,747,047\n",
      "Trainable params: 684,033\n",
      "Non-trainable params: 4,063,014\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 40, 1206)          4063014   \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 39, 256)           617728    \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 36, 64)            65600     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_9 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 4,747,047\n",
      "Trainable params: 684,033\n",
      "Non-trainable params: 4,063,014\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 40, 1206)          4063014   \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 39, 256)           617728    \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 36, 64)            65600     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_10 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 4,747,047\n",
      "Trainable params: 684,033\n",
      "Non-trainable params: 4,063,014\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 40, 1206)          4063014   \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 39, 256)           617728    \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 36, 64)            65600     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_11 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 4,747,047\n",
      "Trainable params: 684,033\n",
      "Non-trainable params: 4,063,014\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 40, 50)            200000    \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 38, 512)           77312     \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 35, 128)           262272    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_12 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 20)                2580      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 542,269\n",
      "Trainable params: 542,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 40, 50)            200000    \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 38, 512)           77312     \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 35, 128)           262272    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_13 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 20)                2580      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 542,269\n",
      "Trainable params: 542,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 40, 50)            200000    \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 38, 512)           77312     \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 35, 128)           262272    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_14 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 20)                2580      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 542,269\n",
      "Trainable params: 542,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 40, 50)            200000    \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 38, 512)           77312     \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 35, 128)           262272    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_15 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 20)                2580      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 542,269\n",
      "Trainable params: 542,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 10, 1206)          4063014   \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 9, 128)            308864    \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 7, 16)             6160      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_16 (Glo (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 5)                 85        \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 5)                 30        \n",
      "=================================================================\n",
      "Total params: 4,378,153\n",
      "Trainable params: 315,139\n",
      "Non-trainable params: 4,063,014\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_16_input'), name='embedding_16_input', description=\"created by layer 'embedding_16_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_16_input'), name='embedding_16_input', description=\"created by layer 'embedding_16_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_16_input'), name='embedding_16_input', description=\"created by layer 'embedding_16_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 10, 1206)          4063014   \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 9, 128)            308864    \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 7, 16)             6160      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_17 (Glo (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 5)                 85        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 5)                 30        \n",
      "=================================================================\n",
      "Total params: 4,378,153\n",
      "Trainable params: 315,139\n",
      "Non-trainable params: 4,063,014\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_17_input'), name='embedding_17_input', description=\"created by layer 'embedding_17_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_17_input'), name='embedding_17_input', description=\"created by layer 'embedding_17_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_17_input'), name='embedding_17_input', description=\"created by layer 'embedding_17_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 10, 1206)          4063014   \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 9, 128)            308864    \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 7, 16)             6160      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_18 (Glo (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 5)                 85        \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 5)                 30        \n",
      "=================================================================\n",
      "Total params: 4,378,153\n",
      "Trainable params: 315,139\n",
      "Non-trainable params: 4,063,014\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_18_input'), name='embedding_18_input', description=\"created by layer 'embedding_18_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_18_input'), name='embedding_18_input', description=\"created by layer 'embedding_18_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_18_input'), name='embedding_18_input', description=\"created by layer 'embedding_18_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 10, 1206)          4063014   \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 9, 128)            308864    \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 7, 16)             6160      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_19 (Glo (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 5)                 85        \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 5)                 30        \n",
      "=================================================================\n",
      "Total params: 4,378,153\n",
      "Trainable params: 315,139\n",
      "Non-trainable params: 4,063,014\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_19_input'), name='embedding_19_input', description=\"created by layer 'embedding_19_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_19_input'), name='embedding_19_input', description=\"created by layer 'embedding_19_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_19_input'), name='embedding_19_input', description=\"created by layer 'embedding_19_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 10, 1206)          4063014   \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 9, 128)            308864    \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 7, 16)             6160      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_20 (Glo (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 5)                 85        \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 5)                 30        \n",
      "=================================================================\n",
      "Total params: 4,378,153\n",
      "Trainable params: 315,139\n",
      "Non-trainable params: 4,063,014\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_20_input'), name='embedding_20_input', description=\"created by layer 'embedding_20_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_20_input'), name='embedding_20_input', description=\"created by layer 'embedding_20_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_20_input'), name='embedding_20_input', description=\"created by layer 'embedding_20_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      " label accuracy could not be calculated\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_20_input'), name='embedding_20_input', description=\"created by layer 'embedding_20_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "Best Test Accuracy was:  0.8064516186714172\n"
     ]
    }
   ],
   "source": [
    "model_output = modelling.hyperparameter_optimization( \n",
    "                            X_train = data['X_train'], \n",
    "                            Y_train = data['Y_train'], \n",
    "                            X_test = data['X_test'], \n",
    "                            Y_test = data['Y_test'] , \n",
    "                            epochs = data['epochs'] , \n",
    "                            batch_size = data['batch_size'],\n",
    "                            param_grid = param_grid,\n",
    "                            cv = data['cv'], \n",
    "                            n_iter = data['n_iter'],\n",
    "                            verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['best_train_acc', 'best_train_param', 'test_acc', 'conf_matrix', 'Y_pred', 'grid_result'])"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "model_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy for label 0 :  90.27  %\nAccuracy for label 1 :  50.0  %\nAccuracy for label 2 :  24.14  %\nAccuracy for label 3 :  66.67  %\nAccuracy for label 4 :  36.0  %\n"
     ]
    }
   ],
   "source": [
    "# Generate Confusion Matrix\n",
    "conf_matrix = confusion_matrix(model_output['Y_pred'], data['Y_test'].argmax(axis=1)) / len(model_output['Y_pred'])\n",
    "\n",
    "# Calculate Label Accuracy\n",
    "model_output['label_acc'] = postprocessing.cal_label_accuracy(conf_matrix, verbose  = 1)"
   ]
  },
  {
   "source": [
    "## 6. Write Results to text file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writting results...\nRunning CNN Modeling \n \n            Best Accuracy : 0.7927031525925025\n  \n            Test Accuracy : 0.8064516186714172\n\n            epochs : 30 \n\n            batch size : 16 \n\n            cross validations : 4 \n\n            No. Iterations : 5 \n\n            sent_tokenizer : False \n   \n            use_nltk_cleaning: False\n \n            text_cleaning: True\n  \n            use_tfidf_tokenizer: False\n \n            use_keras_tokenizer: True\n \n            use_pretrained_embeddings: True\n \n            use_glove_pretrained_embeddings_weights: False\n \n            use_tfidf_as_embedding_weights: True\n \n            best param: {'vocab_size': 6000, 'use_pretrained_embeddings': True, 'seq_input_len': 10, 'output_label': 5, 'num_filters_cv': [128, 16], 'nodes_hidden_dense_layer': 5, 'kernel_size_cv': [2, 3], 'embedding_matrix': array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]]), 'embedding_dim': 40}\n \n            label accuracy: {0: 90.27, 1: 50.0, 2: 24.14, 3: 66.67, 4: 36.0}\n"
     ]
    }
   ],
   "source": [
    "postprocessing.write_results_txt(output_file = data['output_file'], \n",
    "                  best_train_acc = model_output['best_train_acc'], \n",
    "                  best_train_param = model_output['best_train_param'],\n",
    "                  test_acc = model_output['test_acc'], \n",
    "                  label_acc = model_output['label_acc'] , \n",
    "                  sent_tokenizer = sent_tokenizer, \n",
    "                  use_nltk_cleaning = use_nltk_cleaning, \n",
    "                  text_cleaning = text_cleaning , \n",
    "                  use_tfidf_tokenizer = use_tfidf_tokenizer, \n",
    "                  use_keras_tokenizer = use_keras_tokenizer, \n",
    "                  use_pretrained_embeddings = use_pretrained_embeddings,\n",
    "                  use_glove_pretrained_embeddings_weights = use_glove_pretrained_embeddings_weights,\n",
    "                  use_tfidf_as_embedding_weights = use_tfidf_as_embedding_weights,\n",
    "                  epochs = data['epochs'],\n",
    "                  batch_size = data['batch_size'],\n",
    "                  num_words = data['num_words'], \n",
    "                  cv = data['cv'] ,\n",
    "                  n_iter = data['n_iter']\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('class': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a859f67d4acffa6abd10af9224a6e751dd4159d06149102e129e99dcb493c1c8"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}