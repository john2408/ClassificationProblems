{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from datetime import datetime\n",
    "from os import getcwd\n",
    "from os.path import join\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "\n",
    "from sys import path\n",
    "path.append( join( join( getcwd() , 'functions/' ) ) )\n",
    "\n",
    "from functions import preprocessing, modelling, postprocessing\n",
    "from config import ConfigDict\n",
    "\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigDict.read('config/config_param_multiple.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'params': {'model': {'running_CNN': True, 'running_SVM': True, 'seed': 123},\n",
       "  'input_data': {'data': 'data/ML_data_2.0.xlsx',\n",
       "   'sep': ',',\n",
       "   'read_type': 'excel'},\n",
       "  'tokenization_options': {'sent_tokenizer': False,\n",
       "   'use_nltk_cleaning': True,\n",
       "   'text_cleaning': False,\n",
       "   'use_tfidf_tokenizer': True,\n",
       "   'use_keras_tokenizer': False,\n",
       "   'use_pretrained_embeddings': True,\n",
       "   'use_glove_pretrained_embeddings_weights': False,\n",
       "   'use_tfidf_as_embedding_weights': True,\n",
       "   'imbalanced_classes': True,\n",
       "   'make_all_other_classes_1': False,\n",
       "   'remove_class_0': True},\n",
       "  'data': {'epochs': 30,\n",
       "   'batch_size': 16,\n",
       "   'num_words': 5000,\n",
       "   'cv': 4,\n",
       "   'n_iter': 5,\n",
       "   'seq_input_len': 40,\n",
       "   'embedding_dim': 40,\n",
       "   'nodes_hidden_dense_layer': 5,\n",
       "   'filepath': 'D:/Semillero Data Science/Deep Learning/pre-trained Word Embeddings/GloVe/glove.6B.50d.txt',\n",
       "   'SVM': {'C': 1.0,\n",
       "    'kernel': 'linear',\n",
       "    'degree': 3,\n",
       "    'gamma': 'auto',\n",
       "    'class_weights': {'0': 0.05, '1': 1, '2': 1, '3': 1, '4': 1},\n",
       "    'class_weights_2': {'0': 0.7, '1': 1},\n",
       "    'class_weights_1_2_3_4': {'0': 1, '1': 1, '2': 1, '3': 1}}},\n",
       "  'hyperparam': {'num_filters_cv': [[64, 16], [64, 32], [128, 16], [128, 32], [256, 64], [256, 32], [256, 64], [512, 128], [512, 32]],\n",
       "   'kernel_size_cv': [[2, 3], [2, 4], [3, 4], [3, 5]],\n",
       "   'vocab_size': [3000, 4000, 5000, 6000],\n",
       "   'embedding_dim': [20, 30, 40, 50],\n",
       "   'seq_input_len': [50, 40, 30, 20, 10],\n",
       "   'nodes_hidden_dense_layer': [5, 10, 15, 20, 40],\n",
       "   'use_pretrained_embeddings': [True, False]}}}"
      ]
     },
     "metadata": {},
     "execution_count": 151
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(config['params']['model']['seed'])\n",
    "\n",
    "# Current Date\n",
    "current_time = datetime.now().strftime(\"%d-%m-%Y_%H_%M_%S\")\n",
    "\n",
    "# Input data\n",
    "input_data = config['params']['input_data']['data']\n",
    "read_type  = config['params']['input_data']['read_type']\n",
    "\n",
    "# Models to run\n",
    "running_CNN = config['params']['model']['running_CNN']\n",
    "running_SVM = config['params']['model']['running_SVM']\n",
    "\n",
    "# To test for only clases 0 and 1\n",
    "make_all_other_classes_1 =  config['params']['tokenization_options']['make_all_other_classes_1']\n",
    "remove_class_0 = config['params']['tokenization_options']['remove_class_0']\n",
    "\n",
    "\n",
    "# Sentence Tokenizer\n",
    "sent_tokenizer = config['params']['tokenization_options']['sent_tokenizer'] # TODO: Adjust for input to CNN\n",
    "\n",
    "# Text Cleaning Options\n",
    "use_nltk_cleaning = config['params']['tokenization_options']['use_nltk_cleaning']\n",
    "text_cleaning = config['params']['tokenization_options']['text_cleaning']\n",
    "\n",
    "# Word Tokenizer Options\n",
    "use_tfidf_tokenizer = config['params']['tokenization_options']['use_tfidf_tokenizer'] # For SVM\n",
    "use_keras_tokenizer = config['params']['tokenization_options']['use_keras_tokenizer'] # For CNN\n",
    "\n",
    "# If set to FALSE then keras embedding space training is used instead\n",
    "# Embedding Space possibilites are GloVe or TFIDF\n",
    "use_pretrained_embeddings = config['params']['tokenization_options']['use_pretrained_embeddings']\n",
    "\n",
    "# Only if use_pretrained_embeddings == True then select embedding vector space type\n",
    "use_glove_pretrained_embeddings_weights = config['params']['tokenization_options']['use_glove_pretrained_embeddings_weights']\n",
    "use_tfidf_as_embedding_weights = config['params']['tokenization_options']['use_tfidf_as_embedding_weights']\n",
    "\n",
    "# Options for SVM\n",
    "imbalanced_classes = config['params']['tokenization_options']['imbalanced_classes']\n",
    "C = config['params']['data']['SVM']['C']\n",
    "kernel = config['params']['data']['SVM']['kernel']\n",
    "degree = config['params']['data']['SVM']['degree']\n",
    "gamma = config['params']['data']['SVM']['gamma']\n",
    "\n",
    "class_weight = {0: config['params']['data']['SVM']['class_weights']['0'],\n",
    "                1: config['params']['data']['SVM']['class_weights']['1'],\n",
    "                2: config['params']['data']['SVM']['class_weights']['2'],\n",
    "                3: config['params']['data']['SVM']['class_weights']['3'],\n",
    "                4: config['params']['data']['SVM']['class_weights']['4']}\n",
    "\n",
    "\n",
    "class_weight_2 = {0: config['params']['data']['SVM']['class_weights_2']['0'],\n",
    "                1: config['params']['data']['SVM']['class_weights_2']['1']}\n",
    "\n",
    "# Remember that without the 0 , the other labels are reindexed\n",
    "class_weights_1_2_3_4 = {0: config['params']['data']['SVM']['class_weights_1_2_3_4']['0'],\n",
    "                1: config['params']['data']['SVM']['class_weights_1_2_3_4']['1'],\n",
    "                2: config['params']['data']['SVM']['class_weights_1_2_3_4']['2'],\n",
    "                3: config['params']['data']['SVM']['class_weights_1_2_3_4']['3']}\n",
    "\n",
    "# Dictionary which will cotain all the model's variables\n",
    "data = {}\n",
    "\n",
    "# Initialize Model\n",
    "data['epochs'] = config['params']['data']['epochs'] # NO. of optimizatoin runs\n",
    "data['batch_size'] = config['params']['data']['batch_size'] # No. of sentences batch to train\n",
    "data['num_words'] = config['params']['data']['num_words'] # No. of words to use in the embedding space of GloVe or TFIDF\n",
    "data['cv'] = config['params']['data']['cv'] # No. of Cross Validations\n",
    "data['n_iter'] = config['params']['data']['n_iter'] # No. of Iterations\n",
    "data['seq_input_len'] = config['params']['data']['seq_input_len'] # Length of the vector sentence ( no. of words per sentence)\n",
    "data['embedding_dim'] = config['params']['data']['embedding_dim'] # Length of the word vector ( dimension in the embedding space)\n",
    "data['nodes_hidden_dense_layer'] = config['params']['data']['nodes_hidden_dense_layer'] # No. of nodes for hidden Dense layer\n",
    "\n",
    "\n",
    "data['filepath'] = config['params']['data']['filepath'] # File path to GLoVe pretrained embedding words\n",
    "data['output_file'] = f\"results/{current_time}_Result.txt\" # Name of output result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(num_filters_cv = config['params']['hyperparam']['num_filters_cv'], # No of filter to use in convolution\n",
    "                  kernel_size_cv = config['params']['hyperparam']['kernel_size_cv'], # No of words to check per Convolution \n",
    "                  vocab_size = config['params']['hyperparam']['vocab_size'], # Vocab size if keras embedding space training is wanted\n",
    "                  embedding_dim = config['params']['hyperparam']['embedding_dim'], \n",
    "                  seq_input_len = config['params']['hyperparam']['seq_input_len'], \n",
    "                  nodes_hidden_dense_layer = config['params']['hyperparam']['nodes_hidden_dense_layer'],\n",
    "                  use_pretrained_embeddings = config['params']['hyperparam']['use_pretrained_embeddings']\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'data/ML_data_2.0.xlsx'"
      ]
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_type == 'excel':\n",
    "    \n",
    "    corpus = pd.read_excel(input_data, engine='openpyxl')\n",
    "\n",
    "elif read_type == 'csv':\n",
    "\n",
    "    corpus = pd.read_csv( input_data, sep = config['params']['input_data']['sep'])\n",
    "\n",
    "\n",
    "# Filter all NAs values\n",
    "corpus.dropna(inplace= True)\n",
    "corpus['label'] = corpus['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 2006 entries, 0 to 2006\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   text    2006 non-null   object\n 1   label   2006 non-null   int32 \ndtypes: int32(1), object(1)\nmemory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = preprocessing.data_cleaning(corpus = corpus,\n",
    "                       sent_tokenizer = False, \n",
    "                       text_cleaning = True, \n",
    "                       use_nltk_cleaning = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  stable way business life many corporate purcha...      0\n",
       "1  dozens companies already learned supply demand...      0\n",
       "2  capabilities profitable international business...      0\n",
       "3    almost every kind manufacturer answer questions      0\n",
       "4      companies already responded growing pressures      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>stable way business life many corporate purcha...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dozens companies already learned supply demand...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>capabilities profitable international business...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>almost every kind manufacturer answer questions</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>companies already responded growing pressures</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2006 entries, 0 to 2005\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   text    2006 non-null   object\n 1   label   2006 non-null   int32 \ndtypes: int32(1), object(1)\nmemory usage: 23.6+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Filter on the data to avoid the imbalance classes problem\n",
    "if make_all_other_classes_1:\n",
    "\n",
    "    corpus['label_orignal'] = corpus.loc[:,'label']\n",
    "    corpus['label'] = np.where( corpus['label'] > 0 , 1, corpus['label'])\n",
    "\n",
    "elif remove_class_0:\n",
    "\n",
    "    corpus['label_orignal'] = corpus.loc[:,'label']\n",
    "    corpus = corpus[~corpus['label'].isin([0])]\n",
    "    corpus['label'] = corpus['label'].map({1:0,2:1,3:2,4:3})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "remove_class_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2    158\n",
       "3    141\n",
       "1    125\n",
       "0    114\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "corpus['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = preprocessing.prepare_training_data(corpus = corpus, test_size = 0.25)\n",
    "\n",
    "# Concat two dictionaries\n",
    "data = {**data, **model_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['epochs', 'batch_size', 'num_words', 'cv', 'n_iter', 'seq_input_len', 'embedding_dim', 'nodes_hidden_dense_layer', 'filepath', 'output_file', 'sentences_train_SVM', 'sentences_test_SVM', 'Y_train_SVM', 'Y_test_SVM', 'sentences_train_CNN', 'sentences_test_CNN', 'Y_train_CNN', 'Y_test_CNN', 'output_label'])"
      ]
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "if running_CNN:\n",
    "    \n",
    "    data['X_train_CNN'], data['X_test_CNN'], data['vocab_size'], data['vocab'] = modelling.keras_tokenizer(num_words = data['num_words'], \n",
    "                                                                                         sentences_train = data['sentences_train_CNN'] , \n",
    "                                                                                         sentences_test = data['sentences_test_CNN'],\n",
    "                                                                                         seq_input_len = data['seq_input_len'])\n",
    "    if use_tfidf_as_embedding_weights:\n",
    "    \n",
    "        data['embedding_matrix'], data['embedding_dim']  = modelling.tfidf_as_embedding_weights(num_words = data['num_words'], \n",
    "                                                                    corpus = corpus, \n",
    "                                                                    sentences_train = data['sentences_train_CNN'])\n",
    "    \n",
    "    elif use_glove_pretrained_embeddings_weights:\n",
    "        \n",
    "        data['embedding_matrix'], data['embedding_dim'] = modelling.fit_pretrained_embedding_space_glove(embedding_dim = data['embedding_dim'], \n",
    "                                                                            filepath = data['filepath'] , \n",
    "                                                                            vocab = data['vocab'])\n",
    "\n",
    "if running_SVM: \n",
    "\n",
    "    data['X_train_SVM'], data['X_test_SVM'], data['vocab_size'], data['vocab'] = modelling.tfidf_tokenizer(num_words = data['num_words'],\n",
    "                                                                                         corpus = corpus,\n",
    "                                                                                         sentences_train = data['sentences_train_SVM'],\n",
    "                                                                                         sentences_test = data['sentences_test_SVM'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['epochs', 'batch_size', 'num_words', 'cv', 'n_iter', 'seq_input_len', 'embedding_dim', 'nodes_hidden_dense_layer', 'filepath', 'output_file', 'sentences_train_SVM', 'sentences_test_SVM', 'Y_train_SVM', 'Y_test_SVM', 'sentences_train_CNN', 'sentences_test_CNN', 'Y_train_CNN', 'Y_test_CNN', 'output_label', 'X_train_CNN', 'X_test_CNN', 'vocab_size', 'vocab', 'embedding_matrix', 'X_train_SVM', 'X_test_SVM'])"
      ]
     },
     "metadata": {},
     "execution_count": 166
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre = modelling.data_vectorization(sentences_train_CNN = data['sentences_train_CNN'], \n",
    "                       sentences_test_CNN = data['sentences_test_CNN'], \n",
    "                       sentences_train_SVM = data['sentences_train_SVM'], \n",
    "                       sentences_test_SVM = data['sentences_test_SVM'], \n",
    "                       num_words = data['num_words'], \n",
    "                       seq_input_len = data['seq_input_len'], \n",
    "                       filepath = data['filepath'],\n",
    "                       corpus = corpus,\n",
    "                       vocab = data['vocab'],\n",
    "                       embedding_dim = data['embedding_dim'],\n",
    "                       running_CNN = running_CNN, \n",
    "                       running_SVM = running_SVM, \n",
    "                       use_tfidf_as_embedding_weights = use_tfidf_as_embedding_weights,\n",
    "                       use_glove_pretrained_embeddings_weights = use_glove_pretrained_embeddings_weights)\n",
    "\n",
    "# Concat two dictionaries\n",
    "data = {**data, **data_pre}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['epochs', 'batch_size', 'num_words', 'cv', 'n_iter', 'seq_input_len', 'embedding_dim', 'nodes_hidden_dense_layer', 'filepath', 'output_file', 'sentences_train_SVM', 'sentences_test_SVM', 'Y_train_SVM', 'Y_test_SVM', 'sentences_train_CNN', 'sentences_test_CNN', 'Y_train_CNN', 'Y_test_CNN', 'output_label', 'X_train_CNN', 'X_test_CNN', 'vocab_size', 'vocab', 'embedding_matrix', 'X_train_SVM', 'X_test_SVM', 'vocab_size_SVM'])"
      ]
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid['embedding_matrix'] = ([data['embedding_matrix']])\n",
    "param_grid['output_label'] = [data['output_label']]"
   ]
  },
  {
   "source": [
    "## 4. Apply Support Vector Machines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVM Accuracy Score ->  75.55555555555556\nAccuracy for label 0 :  56.25  %\nAccuracy for label 1 :  65.63  %\nAccuracy for label 2 :  89.47  %\nAccuracy for label 3 :  87.88  %\nWritting results...\nRunning SVM Modeling \n  \n            Test Accuracy : 75.5556\n\n            C : 1.0\n\n            kernel : linear\n\n            degree : 3\n \n            gamma : auto\n\n            class_weight : {0: 1, 1: 1, 2: 1, 3: 1}\n\n            sent_tokenizer : False \n   \n            use_nltk_cleaning: True\n \n            text_cleaning: False\n  \n            make_all_other_classes_1: False\n  \n            remove_class_0: True \n\n            use_tfidf_tokenizer: True\n \n            use_keras_tokenizer: False\n \n            use_pretrained_embeddings: True\n \n            use_glove_pretrained_embeddings_weights: False\n \n            use_tfidf_as_embedding_weights: True\n \n            imbalanced_classes: True\n \n            label accuracy: {0: 56.25, 1: 65.63, 2: 89.47, 3: 87.88}\n"
     ]
    }
   ],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "\n",
    "if running_CNN: \n",
    "\n",
    "    if imbalanced_classes: \n",
    "        \n",
    "        if make_all_other_classes_1: \n",
    "\n",
    "            SVM = svm.SVC(C = C, \n",
    "                kernel = kernel,\n",
    "                degree = degree, \n",
    "                gamma = gamma,\n",
    "                class_weight = class_weight_2)\n",
    "\n",
    "            class_weight = class_weight_2\n",
    "\n",
    "\n",
    "        elif remove_class_0:\n",
    "\n",
    "            SVM = svm.SVC(C = C, \n",
    "                kernel = kernel,\n",
    "                degree = degree, \n",
    "                gamma = gamma,\n",
    "                class_weight = class_weights_1_2_3_4)\n",
    "\n",
    "            class_weight = class_weights_1_2_3_4\n",
    "\n",
    "        else:\n",
    "\n",
    "            SVM = svm.SVC(C = C, \n",
    "                kernel = kernel,\n",
    "                degree = degree, \n",
    "                gamma = gamma,\n",
    "                class_weight = class_weight)    \n",
    "\n",
    "    else: \n",
    "\n",
    "        SVM = svm.SVC(C = C, \n",
    "                kernel = kernel,\n",
    "                degree = degree, \n",
    "                gamma = gamma,\n",
    "                )\n",
    "\n",
    "    # Fit SVM Model\n",
    "    SVM.fit(data['X_train_SVM'], data['Y_train_SVM'])\n",
    "\n",
    "    # predict the labels on validation dataset\n",
    "    predictions_SVM = SVM.predict(data['X_test_SVM'])\n",
    "\n",
    "    # Use accuracy_score function to get the accuracy\n",
    "    data['test_acc'] = np.round( accuracy_score(predictions_SVM, data['Y_test_SVM'])*100 , 4)\n",
    "\n",
    "    print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM, data['Y_test_SVM'])*100)\n",
    "\n",
    "    # Print Confusion Matrix\n",
    "    Pred_Y = SVM.predict(data['X_train_SVM'])\n",
    "    data['conf_matrix'] = confusion_matrix(data['Y_test_SVM'], predictions_SVM)/len(predictions_SVM)\n",
    "\n",
    "    # Calculate Label Accuracy\n",
    "    data['label_acc'] = postprocessing.cal_label_accuracy(data['conf_matrix'], verbose  = 1)\n",
    "\n",
    "    postprocessing.write_results_txt_SVM( output_file = data['output_file'],  \n",
    "                      test_acc = data['test_acc'] , \n",
    "                      label_acc = data['label_acc'], \n",
    "                      sent_tokenizer = sent_tokenizer, \n",
    "                      use_nltk_cleaning = use_nltk_cleaning, \n",
    "                      text_cleaning = text_cleaning , \n",
    "                      use_tfidf_tokenizer = use_tfidf_tokenizer, \n",
    "                      use_keras_tokenizer = use_keras_tokenizer, \n",
    "                      use_pretrained_embeddings = use_pretrained_embeddings,\n",
    "                      use_glove_pretrained_embeddings_weights = use_glove_pretrained_embeddings_weights,\n",
    "                      use_tfidf_as_embedding_weights = use_tfidf_as_embedding_weights,\n",
    "                      imbalanced_classes = imbalanced_classes,\n",
    "                      make_all_other_classes_1 = make_all_other_classes_1,\n",
    "                      remove_class_0 = remove_class_0,\n",
    "                      C = C ,\n",
    "                      kernel = kernel,\n",
    "                      degree = degree, \n",
    "                      gamma = gamma,\n",
    "                      class_weight = class_weight )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Convolutional Neural Networks\n",
    "\n",
    "Reference: https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "================\n",
      "Total params: 893,990\n",
      "Trainable params: 256,847\n",
      "Non-trainable params: 637,143\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_12_input'), name='embedding_12_input', description=\"created by layer 'embedding_12_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_12_input'), name='embedding_12_input', description=\"created by layer 'embedding_12_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_12_input'), name='embedding_12_input', description=\"created by layer 'embedding_12_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 10, 403)           637143    \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 9, 256)            206592    \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 7, 64)             49216     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_13 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 15)                975       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 4)                 64        \n",
      "=================================================================\n",
      "Total params: 893,990\n",
      "Trainable params: 256,847\n",
      "Non-trainable params: 637,143\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_13_input'), name='embedding_13_input', description=\"created by layer 'embedding_13_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_13_input'), name='embedding_13_input', description=\"created by layer 'embedding_13_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_13_input'), name='embedding_13_input', description=\"created by layer 'embedding_13_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 10, 403)           637143    \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 9, 256)            206592    \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 7, 64)             49216     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_14 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 15)                975       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4)                 64        \n",
      "=================================================================\n",
      "Total params: 893,990\n",
      "Trainable params: 256,847\n",
      "Non-trainable params: 637,143\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_14_input'), name='embedding_14_input', description=\"created by layer 'embedding_14_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_14_input'), name='embedding_14_input', description=\"created by layer 'embedding_14_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_14_input'), name='embedding_14_input', description=\"created by layer 'embedding_14_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 10, 403)           637143    \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 9, 256)            206592    \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 7, 64)             49216     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_15 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 15)                975       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 4)                 64        \n",
      "=================================================================\n",
      "Total params: 893,990\n",
      "Trainable params: 256,847\n",
      "Non-trainable params: 637,143\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_15_input'), name='embedding_15_input', description=\"created by layer 'embedding_15_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_15_input'), name='embedding_15_input', description=\"created by layer 'embedding_15_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_15_input'), name='embedding_15_input', description=\"created by layer 'embedding_15_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 30, 20)            60000     \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 28, 256)           15616     \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 24, 32)            40992     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_16 (Glo (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 40)                1320      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 4)                 164       \n",
      "=================================================================\n",
      "Total params: 118,092\n",
      "Trainable params: 118,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_16_input'), name='embedding_16_input', description=\"created by layer 'embedding_16_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_16_input'), name='embedding_16_input', description=\"created by layer 'embedding_16_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_16_input'), name='embedding_16_input', description=\"created by layer 'embedding_16_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 30, 20)            60000     \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 28, 256)           15616     \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 24, 32)            40992     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_17 (Glo (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 40)                1320      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 4)                 164       \n",
      "=================================================================\n",
      "Total params: 118,092\n",
      "Trainable params: 118,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_17_input'), name='embedding_17_input', description=\"created by layer 'embedding_17_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_17_input'), name='embedding_17_input', description=\"created by layer 'embedding_17_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_17_input'), name='embedding_17_input', description=\"created by layer 'embedding_17_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 30, 20)            60000     \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 28, 256)           15616     \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 24, 32)            40992     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_18 (Glo (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 40)                1320      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 4)                 164       \n",
      "=================================================================\n",
      "Total params: 118,092\n",
      "Trainable params: 118,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_18_input'), name='embedding_18_input', description=\"created by layer 'embedding_18_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_18_input'), name='embedding_18_input', description=\"created by layer 'embedding_18_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_18_input'), name='embedding_18_input', description=\"created by layer 'embedding_18_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 30, 20)            60000     \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 28, 256)           15616     \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 24, 32)            40992     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_19 (Glo (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 40)                1320      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 4)                 164       \n",
      "=================================================================\n",
      "Total params: 118,092\n",
      "Trainable params: 118,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_19_input'), name='embedding_19_input', description=\"created by layer 'embedding_19_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_19_input'), name='embedding_19_input', description=\"created by layer 'embedding_19_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_19_input'), name='embedding_19_input', description=\"created by layer 'embedding_19_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 10, 403)           637143    \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 9, 256)            206592    \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 7, 64)             49216     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_20 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 15)                975       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 4)                 64        \n",
      "=================================================================\n",
      "Total params: 893,990\n",
      "Trainable params: 256,847\n",
      "Non-trainable params: 637,143\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_20_input'), name='embedding_20_input', description=\"created by layer 'embedding_20_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_20_input'), name='embedding_20_input', description=\"created by layer 'embedding_20_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_20_input'), name='embedding_20_input', description=\"created by layer 'embedding_20_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      " label accuracy could not be calculated\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_20_input'), name='embedding_20_input', description=\"created by layer 'embedding_20_input'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "Best Test Accuracy was:  0.6592592597007751\n",
      "Accuracy for label 0 :  59.38  %\n",
      "Accuracy for label 1 :  68.0  %\n",
      "Accuracy for label 2 :  64.44  %\n",
      "Accuracy for label 3 :  72.73  %\n",
      "Writting results...\n",
      "Running CNN Modeling \n",
      " \n",
      "            Best Accuracy : 0.5955335043795943\n",
      "  \n",
      "            Test Accuracy : 0.6592592597007751\n",
      "\n",
      "            epochs : 30 \n",
      "\n",
      "            batch size : 16 \n",
      "\n",
      "            cross validations : 4 \n",
      "\n",
      "            No. Iterations : 5 \n",
      "\n",
      "            sent_tokenizer : False \n",
      "   \n",
      "            use_nltk_cleaning: True\n",
      " \n",
      "            text_cleaning: False\n",
      "  \n",
      "            use_tfidf_tokenizer: True\n",
      " \n",
      "            use_keras_tokenizer: False\n",
      " \n",
      "            use_pretrained_embeddings: True\n",
      " \n",
      "            use_glove_pretrained_embeddings_weights: False\n",
      " \n",
      "            use_tfidf_as_embedding_weights: True\n",
      " \n",
      "            best param: {'vocab_size': 5000, 'use_pretrained_embeddings': True, 'seq_input_len': 10, 'output_label': 4, 'num_filters_cv': [256, 64], 'nodes_hidden_dense_layer': 15, 'kernel_size_cv': [2, 3], 'embedding_matrix': array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.32944235, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ]]), 'embedding_dim': 30}\n",
      " \n",
      "            label accuracy: {0: 59.38, 1: 68.0, 2: 64.44, 3: 72.73}\n"
     ]
    }
   ],
   "source": [
    "if running_CNN:\n",
    "\n",
    "    model_output = modelling.hyperparameter_optimization( \n",
    "                                X_train = data['X_train_CNN'], \n",
    "                                Y_train = data['Y_train_CNN'], \n",
    "                                X_test = data['X_test_CNN'], \n",
    "                                Y_test = data['Y_test_CNN'] , \n",
    "                                epochs = data['epochs'] , \n",
    "                                batch_size = data['batch_size'],\n",
    "                                param_grid = param_grid,\n",
    "                                cv = data['cv'], \n",
    "                                n_iter = data['n_iter'],\n",
    "                                verbose = False)\n",
    "\n",
    "    # 5. Score Analysis\n",
    "\n",
    "    # Generate Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(model_output['Y_pred'], data['Y_test_CNN'].argmax(axis=1)) / len(model_output['Y_pred'])\n",
    "\n",
    "    # Calculate Label Accuracy\n",
    "    model_output['label_acc'] = postprocessing.cal_label_accuracy(conf_matrix, verbose  = 1)\n",
    "\n",
    "    # 6. Write Results to text file\n",
    "    postprocessing.write_results_txt_CNN(output_file = data['output_file'], \n",
    "                  best_train_acc = model_output['best_train_acc'], \n",
    "                  best_train_param = model_output['best_train_param'],\n",
    "                  test_acc = model_output['test_acc'], \n",
    "                  label_acc = model_output['label_acc'] , \n",
    "                  sent_tokenizer = sent_tokenizer, \n",
    "                  use_nltk_cleaning = use_nltk_cleaning, \n",
    "                  text_cleaning = text_cleaning , \n",
    "                  use_tfidf_tokenizer = use_tfidf_tokenizer, \n",
    "                  use_keras_tokenizer = use_keras_tokenizer, \n",
    "                  use_pretrained_embeddings = use_pretrained_embeddings,\n",
    "                  use_glove_pretrained_embeddings_weights = use_glove_pretrained_embeddings_weights,\n",
    "                  use_tfidf_as_embedding_weights = use_tfidf_as_embedding_weights,\n",
    "                  epochs = data['epochs'],\n",
    "                  batch_size = data['batch_size'],\n",
    "                  num_words = data['num_words'], \n",
    "                  cv = data['cv'] ,\n",
    "                  n_iter = data['n_iter']\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('class': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a859f67d4acffa6abd10af9224a6e751dd4159d06149102e129e99dcb493c1c8"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}