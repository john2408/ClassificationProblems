{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import getcwd, path\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from re import compile\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num CPUs Available:  1\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11112785215170516138\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.config.experimental import list_physical_devices\n",
    "print(\"Num CPUs Available: \", len(list_physical_devices('CPU')))\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenizer = False # NOt implemented\n",
    "use_pretrained_embeddings = True\n",
    "\n",
    "use_nltk_cleaning = False\n",
    "text_cleaning = True\n",
    "\n",
    "use_tfidf_tokenizer = True  # TODO: Adjust for input to CNN\n",
    "use_keras_tokenizer = False\n",
    "\n",
    "use_tfidf_as_embedding_weights = False\n",
    "use_pretrained_embeddings = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    \n",
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    \n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                    vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "def cal_label_accuracy(conf_matrix, verbose = 0):\n",
    "    \n",
    "    label_acc = {}\n",
    "    \n",
    "    for index, x in enumerate(conf_matrix): \n",
    "        \n",
    "        label_acc[index] = np.round( conf_matrix[index][index]/ sum(conf_matrix[index]) *100 , 2)\n",
    "        \n",
    "        if verbose > 0:\n",
    "        \n",
    "            print(\"Accuracy for label\", index, \": \", label_acc[index] , \" %\" )\n",
    "    \n",
    "    return label_acc\n",
    "\n",
    "    \n",
    "def clean_text(text):\n",
    "        \"\"\"\n",
    "            text: a string\n",
    "\n",
    "            return: modified initial string\n",
    "        \"\"\"\n",
    "        text = text.lower() # lowercase text\n",
    "        text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "        text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "        text = text.replace('x', '')\n",
    "        text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use 5 Category Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'D:/Data_Science/ClassificationProblems/Sentiment_Analysis/data/SA_4_Categories.csv'\n",
    "corpus = pd.read_csv(data_dir ,encoding='latin-1', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use 2 Category Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_path = getcwd()\n",
    "\n",
    "# filepath_dict = {'yelp':   'data/yelp_labelled.txt',\n",
    "#                  'amazon': 'data/amazon_cells_labelled.txt',\n",
    "#                  'imdb':   'data/imdb_labelled.txt'}\n",
    "\n",
    "# df_list = []\n",
    "\n",
    "# for source, filepath in filepath_dict.items():\n",
    "    \n",
    "#     df = pd.read_csv(path.join(current_path, filepath), names=['sentence', 'label'], sep='\\t')\n",
    "#     df['source'] = source  # Add another column filled with the source name\n",
    "#     df_list.append(df)\n",
    "\n",
    "# df = pd.concat(df_list)\n",
    "# df.rename(columns = {'sentence':'text'}, inplace = True)\n",
    "# corpus = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The stable way of business life many corporate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As dozens of companies have already learned, s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What capabilities will a profitable internatio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Almost every kind of manufacturer will have to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some companies have already responded to the g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  The stable way of business life many corporate...      0\n",
       "1  As dozens of companies have already learned, s...      0\n",
       "2  What capabilities will a profitable internatio...      0\n",
       "3  Almost every kind of manufacturer will have to...      0\n",
       "4  Some companies have already responded to the g...      0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1609 entries, 0 to 1608\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    1609 non-null   object\n",
      " 1   label   1609 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 25.3+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "if text_cleaning:\n",
    "\n",
    "    corpus = corpus.reset_index(drop=True)\n",
    "\n",
    "    REPLACE_BY_SPACE_RE = compile('[/(){}\\[\\]\\|@,;]')\n",
    "    BAD_SYMBOLS_RE = compile('[^0-9a-z #+_]')\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "  \n",
    "    corpus['text'] = corpus['text'].apply(clean_text)\n",
    "    corpus['text'] = corpus['text'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stable way business life many corporate purcha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dozens companies already learned supply demand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capabilities profitable international business...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>almost every kind manufacturer answer questions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>companies already responded growing pressures</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  stable way business life many corporate purcha...      0\n",
       "1  dozens companies already learned supply demand...      0\n",
       "2  capabilities profitable international business...      0\n",
       "3    almost every kind manufacturer answer questions      0\n",
       "4      companies already responded growing pressures      0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NLTK - Data preprocessing\n",
    "\n",
    "- I. Remove Blank rows in Data, if any\n",
    "- II. Change all the text to lower case\n",
    "- III. Word Tokenization\n",
    "- IV. Remove Stop words\n",
    "- V. Remove Non-alpha text\n",
    "- VI. Word Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_nltk_cleaning:\n",
    "\n",
    "    # Step III : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "    if sent_tokenizer: \n",
    "        corpus['text'] = [sent_tokenize(x) for x in corpus['text']] \n",
    "    else:\n",
    "        #Corpus['text'] = Corpus['text'].apply(lambda x: str(word_tokenize(x)) )\n",
    "        corpus['text'] = [word_tokenize(x) for x in corpus['text']]\n",
    "\n",
    "    # Step IV, V, VI : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "    # WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "    # Word Classification for Lemmatizer https://www.nltk.org/_modules/nltk/corpus/reader/wordnet.html\n",
    "    # https://www.geeksforgeeks.org/defaultdict-in-python/\n",
    "    tag_map = defaultdict(lambda: wn.NOUN)\n",
    "    tag_map['J'] = wn.ADJ\n",
    "    tag_map['V'] = wn.VERB\n",
    "    tag_map['R'] = wn.ADV\n",
    "\n",
    "    # Execute Word Tagging\n",
    "    for index, entry in enumerate(corpus['text']):\n",
    "\n",
    "        # Declaring Empty List to store the words that follow the rules for this step\n",
    "        lemma_words = []\n",
    "\n",
    "        # Initializing WordNetLemmatizer()\n",
    "        word_Lemmatized = WordNetLemmatizer()\n",
    "\n",
    "        # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "        # Posttagging reference : https://www.nltk.org/book/ch05.html \n",
    "\n",
    "        for word, tag in pos_tag(entry):\n",
    "\n",
    "            # Below condition is to check for Stop words and consider only alphabets\n",
    "            # List of stop words https://gist.github.com/sebleier/554280, https://www.nltk.org/book/ch02.html\n",
    "\n",
    "            # NLTK check for an alphabetic word https://tedboy.github.io/nlps/generated/generated/nltk.text_type.isalpha.html\n",
    "            if word not in stopwords.words('english') and word.isalpha():\n",
    "\n",
    "                # Reference https://www.geeksforgeeks.org/python-lemmatization-with-nltk/\n",
    "                # Use first letter of NLTK Postagging as \"pos\" parameter mapping it through the dict tag_map\n",
    "                lemma_word = word_Lemmatized.lemmatize(word = word,\n",
    "                                                       pos = tag_map[tag[0]]  )\n",
    "                # Append word back to the empty list\n",
    "                lemma_words.append(lemma_word)\n",
    "\n",
    "        # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "        corpus.loc[index,'text_clean'] = ' '.join(lemma_words)\n",
    "    \n",
    "    corpus.loc[:,'text'] = corpus['text_clean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Trainig and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training X data\n",
    "sentences = corpus['text'].values\n",
    "\n",
    "# Use Label encoder for the expected output\n",
    "Encoder = LabelEncoder()\n",
    "encoded_Y = Encoder.fit_transform(corpus['label'].values)\n",
    "Y = pd.get_dummies(encoded_Y).values\n",
    "\n",
    "sentences_train, sentences_test, Y_train, Y_test = train_test_split( sentences, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (1609, 5)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Word Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "output_label = len(np.unique(encoded_Y))\n",
    "\n",
    "# Append \"0\" add the sentences ending to have equal sentences length\n",
    "seq_input_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_keras_tokenizer:\n",
    "    \n",
    "    # Start Tokenizer Object\n",
    "    tokenizer = Tokenizer(num_words=5000)\n",
    "\n",
    "    # Train vocabulary\n",
    "    tokenizer.fit_on_texts(sentences_train)\n",
    "\n",
    "    X_train = tokenizer.texts_to_sequences(sentences_train) \n",
    "    \n",
    "    \n",
    "    X_test = tokenizer.texts_to_sequences(sentences_test)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "   \n",
    "    vocab = tokenizer.word_index\n",
    "\n",
    "    X_train = pad_sequences(X_train, padding='post', maxlen=seq_input_len)\n",
    "    X_test = pad_sequences(X_test, padding='post', maxlen=seq_input_len)\n",
    "\n",
    "if use_tfidf_tokenizer:\n",
    "    \n",
    "    # Create new Class TfidfVectorizer with max 5000 features\n",
    "    Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "    # Learn vocabulary and idf from training set\n",
    "    Tfidf_vect.fit(corpus['text'])\n",
    "\n",
    "    # Transfor both the train and the test to document-term matrix\n",
    "    X_train = Tfidf_vect.transform(sentences_train)\n",
    "    X_test = Tfidf_vect.transform(sentences_test)\n",
    "    \n",
    "    vocab = Tfidf_vect.vocabulary_\n",
    "    \n",
    "    vocab_size = len(vocab) + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use pre-trained Embedding Space ( GloVe )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_tfidf_as_embedding_weights: \n",
    "     \n",
    "    # Create new Class TfidfVectorizer with max 5000 features\n",
    "    Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "    # Learn vocabulary and idf from training set\n",
    "    Tfidf_vect.fit(corpus['text'])\n",
    "\n",
    "    # Transfor both the train and the test to document-term matrix\n",
    "    embedding_matrix = Tfidf_vect.transform(sentences_train).toarray()\n",
    "    \n",
    "    # Calculate embedding dimension - sequence length\n",
    "    embedding_dim = len(embedding_matrix[1])\n",
    "    \n",
    "if use_pretrained_embeddings: \n",
    "    \n",
    "    embedding_dim = 50\n",
    "    \n",
    "    embedding_matrix = create_embedding_matrix(\n",
    "     filepath = 'D:/Semillero Data Science/Deep Learning/pre-trained Word Embeddings/GloVe/glove.6B.50d.txt',\n",
    "     word_index = vocab, \n",
    "     embedding_dim = embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_dim = 50\n",
    "\n",
    "# embedding_matrix = create_embedding_matrix(\n",
    "#  filepath = 'D:/Semillero Data Science/Deep Learning/pre-trained Word Embeddings/GloVe/glove.6B.50d.txt',\n",
    "#  word_index = vocab, \n",
    "#  embedding_dim = embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3370, 50)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set up CNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_73 (Embedding)     (None, 50, 50)            168500    \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 49, 128)           12928     \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 47, 32)            12320     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_10 (Glo (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 194,133\n",
      "Trainable params: 25,633\n",
      "Non-trainable params: 168,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "if use_pretrained_embeddings:  \n",
    "  \n",
    "    model.add(layers.Embedding(vocab_size, embedding_dim, \n",
    "                               weights=[embedding_matrix], \n",
    "                               input_length=seq_input_len, \n",
    "                               trainable=False))\n",
    "else: \n",
    "    embedding_dim = 100 # Output Dimension - seq output length\n",
    "    model.add(layers.Embedding(vocab_size, embedding_dim, input_length = seq_input_len))\n",
    "\n",
    "# Filters: No. of output filter in the convolution\n",
    "# kernel_size: An integer or tuple/list of a single integer, specifying the length of the 1D convolution window.\n",
    "model.add(layers.Conv1D(filters = 128, kernel_size = 2, activation='relu'))\n",
    "\n",
    "# Global max pooling operation for 1D temporal data.\n",
    "# Downsamples the input representation by taking the maximum value over the time dimension\n",
    "#model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Conv1D(filters = 32, kernel_size = 3, activation='relu'))\n",
    "\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(output_label, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Model - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[1] = [0,2547] is out of order. Many sparse ops require sorted indices.\n    Use `tf.sparse.reorder` to create a correctly ordered copy.\n\n [Op:SerializeManySparse]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-188-411032f45951>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                     batch_size = 10)\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1064\u001b[1;33m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m         model=model)\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    689\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \"\"\"\n\u001b[1;32m--> 691\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m   \u001b[1;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m   3155\u001b[0m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3156\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3157\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3158\u001b[0m     self._structure = nest.map_structure(\n\u001b[0;32m   3159\u001b[0m         lambda component_spec: component_spec._unbatch(), batched_spec)  # pylint: disable=protected-access\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mto_batched_tensor_list\u001b[1;34m(element_spec, element)\u001b[0m\n\u001b[0;32m    364\u001b[0m   return _to_tensor_list_helper(\n\u001b[0;32m    365\u001b[0m       lambda state, spec, component: state + spec._to_batched_tensor_list(\n\u001b[1;32m--> 366\u001b[1;33m           component), element_spec, element)\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36m_to_tensor_list_helper\u001b[1;34m(encode_fn, element_spec, element)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m   return functools.reduce(\n\u001b[1;32m--> 340\u001b[1;33m       reduce_fn, zip(nest.flatten(element_spec), nest.flatten(element)), [])\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mreduce_fn\u001b[1;34m(state, value)\u001b[0m\n\u001b[0;32m    335\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mencode_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m   return functools.reduce(\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(state, spec, component)\u001b[0m\n\u001b[0;32m    364\u001b[0m   return _to_tensor_list_helper(\n\u001b[0;32m    365\u001b[0m       lambda state, spec, component: state + spec._to_batched_tensor_list(\n\u001b[1;32m--> 366\u001b[1;33m           component), element_spec, element)\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py\u001b[0m in \u001b[0;36m_to_batched_tensor_list\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    369\u001b[0m     return [gen_sparse_ops.serialize_many_sparse(\n\u001b[0;32m    370\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m         out_type=dtypes.variant)]\n\u001b[0m\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\ops\\gen_sparse_ops.py\u001b[0m in \u001b[0;36mserialize_many_sparse\u001b[1;34m(sparse_indices, sparse_values, sparse_shape, out_type, name)\u001b[0m\n\u001b[0;32m    493\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    496\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6861\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6862\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6863\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: indices[1] = [0,2547] is out of order. Many sparse ops require sorted indices.\n    Use `tf.sparse.reorder` to create a correctly ordered copy.\n\n [Op:SerializeManySparse]"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    epochs = 30,\n",
    "                    verbose = False,\n",
    "                    validation_data = (X_test, Y_test),\n",
    "                    batch_size = 10)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_train, Y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, Y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for label 0 :  92.56  %\n",
      "Accuracy for label 1 :  30.77  %\n",
      "Accuracy for label 2 :  46.43  %\n",
      "Accuracy for label 3 :  66.67  %\n",
      "Accuracy for label 4 :  27.59  %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 92.56, 1: 30.77, 2: 46.43, 3: 66.67, 4: 27.59}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "conf_matrix = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1)) / len(Y_pred)\n",
    "cal_label_accuracy(conf_matrix, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Model - Recurrent Neural Networks - RNN\n",
    "\n",
    "Reference: https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "if use_pretrained_embeddings:  \n",
    "  \n",
    "    model.add(layers.Embedding(input_dim = vocab_size, \n",
    "                               output_dim = embedding_dim, \n",
    "                               weights = [embedding_matrix], \n",
    "                               input_length = seq_input_len, \n",
    "                               trainable = False))\n",
    "else: \n",
    "    embedding_dim = 100 # Output Dimension - seq output length\n",
    "    model.add(layers.Embedding(vocab_size, embedding_dim, input_length = seq_input_len))\n",
    "    \n",
    "model.add(layers.SpatialDropout1D(0.2))\n",
    "model.add(layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.add(layers.Dense(output_label, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5211\n",
      "Testing Accuracy:  0.5022\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                    Y_train, \n",
    "                    epochs = epochs, \n",
    "                    batch_size = batch_size,\n",
    "                    validation_data = (X_test, Y_test), \n",
    "                    validation_split=0.1,\n",
    "                    verbose = False,\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(X_train, Y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, Y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for label 0 :  4.3  %\n",
      "Accuracy for label 1 :  97.63  %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 4.3, 1: 97.63}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "conf_matrix = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1)) / len(Y_pred)\n",
    "cal_label_accuracy(conf_matrix, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "sent_tokenizer = False\n",
    "\n",
    "use_nltk_cleaning = False\n",
    "\n",
    "use_tfidf_tokenizer = False # TODO: Adjust for input to CNN\n",
    "use_keras_tokenizer = True\n",
    "\n",
    "use_pretrained_embeddings = True\n",
    "use_tfidf_as_embedding_weights = True\n",
    "\n",
    "# Initialize Model\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "output_label = len(np.unique(encoded_Y))\n",
    "num_words = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_tokenizer(sentences_train, sentences_test, num_words, seq_input_len):\n",
    "\n",
    "    # Start Tokenizer Object\n",
    "    tokenizer = Tokenizer(num_words = num_words)\n",
    "\n",
    "    # Train vocabulary\n",
    "    tokenizer.fit_on_texts(sentences_train)\n",
    "\n",
    "    X_train = tokenizer.texts_to_sequences(sentences_train) \n",
    "    X_test = tokenizer.texts_to_sequences(sentences_test)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "    vocab = tokenizer.word_index\n",
    "\n",
    "    X_train = pad_sequences(X_train, padding = 'post', maxlen = seq_input_len)\n",
    "    X_test = pad_sequences(X_test, padding = 'post', maxlen = seq_input_len)\n",
    "\n",
    "    return X_train, X_test, vocab_size, vocab\n",
    "\n",
    "\n",
    "\n",
    "def tfidf_tokenizer(sentences_train, sentences_test, num_words):\n",
    "\n",
    "    # Create new Class TfidfVectorizer with max 5000 features\n",
    "    Tfidf_vect = TfidfVectorizer(max_features=num_words)\n",
    "\n",
    "    # Learn vocabulary and idf from training set\n",
    "    Tfidf_vect.fit(corpus['text'])\n",
    "\n",
    "    # Transfor both the train and the test to document-term matrix\n",
    "    X_train = Tfidf_vect.transform(sentences_train)\n",
    "    X_test = Tfidf_vect.transform(sentences_test)\n",
    "\n",
    "    vocab = list(Tfidf_vect.vocabulary_.keys())\n",
    "\n",
    "    vocab_size = len(vocab) + 1\n",
    "\n",
    "    return X_train, X_test, vocab_size, vocab \n",
    "\n",
    "def create_tfidf_embedding_weights(num_words, sentences_train):\n",
    "\n",
    "    # Create new Class TfidfVectorizer with max 5000 features\n",
    "    Tfidf_vect = TfidfVectorizer(max_features = num_words)\n",
    "\n",
    "    # Learn vocabulary and idf from training set\n",
    "    Tfidf_vect.fit(corpus['text'])\n",
    "\n",
    "    # Transfor both the train and the test to document-term matrix\n",
    "    embedding_matrix = Tfidf_vect.transform(sentences_train)\n",
    "\n",
    "    # Calculate embedding dimension - sequence length\n",
    "    embedding_dim = len(embedding_matrix.toarray()[1])\n",
    "\n",
    "    return embedding_matrix, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model\n",
    "epochs = 30\n",
    "batch_size = 10\n",
    "output_label = len(np.unique(encoded_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(num_filters_cv = [(128,32), (64,16), (128,32), (128,16)],\n",
    "                  kernel_size_cv = [(2,3), (4,5), (5,4), (5,2)],\n",
    "                  vocab_size = [5000, 3000, 6000], \n",
    "                  embedding_dim = [50],\n",
    "                  seq_input_len = [50, 40, 30])\n",
    "\n",
    "# Append \"0\" add the sentences ending to have equal sentences length\n",
    "seq_input_len = 50\n",
    "embedding_dim = 50\n",
    "file_path = 'D:/Semillero Data Science/Deep Learning/pre-trained Word Embeddings/GloVe/glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(sentences_train, \n",
    "                       sentences_test, \n",
    "                       num_words, \n",
    "                       seq_input_len, \n",
    "                       filepath,\n",
    "                       use_keras_tokenizer = True, \n",
    "                       use_tfidf_tokenizer = False, \n",
    "                       use_tfidf_as_embedding_weights = True,\n",
    "                       use_pretrained_embeddings = False):\n",
    "\n",
    "    output = {'X_train' : '', 'X_test' : '', 'vocab_size' : '', 'vocab' : '', 'embedding_matrix' : '', 'embedding_dim': ''}\n",
    "    \n",
    "    if use_keras_tokenizer:\n",
    "        \n",
    "        X_train, X_test, vocab_size, vocab = keras_tokenizer(sentences_train, sentences_test, num_words, seq_input_len)\n",
    "        \n",
    "        output['X_train'] = X_train\n",
    "        output['X_test'] = X_test\n",
    "        output['vocab_size'] = vocab_size\n",
    "        output['vocab'] = vocab\n",
    "        \n",
    "    elif use_tfidf_tokenizer:\n",
    "        \n",
    "        X_train, X_test, vocab_size, vocab = tfidf_tokenizer(sentences_train, sentences_test, num_words)\n",
    "        \n",
    "        output['X_train'] = X_train\n",
    "        output['X_test'] = X_test\n",
    "        output['vocab_size'] = vocab_size\n",
    "        output['vocab'] = vocab\n",
    "    \n",
    "    if use_tfidf_as_embedding_weights: \n",
    "        \n",
    "        embedding_matrix, embedding_dim = create_tfidf_embedding_weights(num_words, sentences_train)\n",
    "        \n",
    "        output['embedding_matrix'] = embedding_matrix\n",
    "        output['embedding_dim'] = embedding_dim\n",
    "    \n",
    "    if use_pretrained_embeddings:  \n",
    "        \n",
    "        embedding_matrix = create_embedding_matrix(\n",
    "                             filepath = filepath,\n",
    "                             word_index = vocab, \n",
    "                             embedding_dim = embedding_dim)\n",
    "        \n",
    "        output['embedding_matrix'] = embedding_matrix\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_filters_cv, kernel_size_cv, vocab_size, embedding_dim, seq_input_len, output_label):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"      \n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    if use_pretrained_embeddings:  \n",
    "\n",
    "        model.add(layers.Embedding(input_dim = vocab_size, \n",
    "                                   output_dim = embedding_dim, \n",
    "                                   weights = [embedding_matrix], \n",
    "                                   input_length = seq_input_len, \n",
    "                                   trainable = False))\n",
    "    else: \n",
    "        \n",
    "        # embedding_dim = 100 # Output Dimension - seq output length\n",
    "        \n",
    "        model.add(layers.Embedding(input_dim = vocab_size, \n",
    "                                   output_dim = embedding_dim, \n",
    "                                   input_length = seq_input_len))\n",
    "\n",
    "    # Filters: No. of output filter in the convolution\n",
    "    # kernel_size: An integer or tuple/list of a single integer, specifying the length of the 1D convolution window.\n",
    "    model.add(layers.Conv1D(filters = num_filters_cv[0], kernel_size = kernel_size_cv[0], activation='relu'))\n",
    "\n",
    "    # Global max pooling operation for 1D temporal data.\n",
    "    # Downsamples the input representation by taking the maximum value over the time dimension\n",
    "    #model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(layers.Conv1D(filters = num_filters_cv[1], kernel_size = kernel_size_cv[1], activation='relu'))\n",
    "\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(output_label, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_optimization(create_model, X_train, Y_train, X_test, Y_test, \n",
    "                                epochs, batch_size, param_grid, cv, n_iter, \n",
    "                                embedding_dim, seq_input_len, output_label,\n",
    "                                vocab_size,\n",
    "                                verbose = 0 ):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"  \n",
    "        \n",
    "\n",
    "    # Create NN Model \n",
    "    model = KerasClassifier(build_fn = create_model,\n",
    "                            epochs = epochs, \n",
    "                            batch_size = batch_size,\n",
    "                            embedding_dim = embedding_dim, \n",
    "                            seq_input_len = seq_input_len,\n",
    "                            output_label = output_label,\n",
    "                            verbose = False)\n",
    "    \n",
    "    # Make Random Search Cross Validation\n",
    "    grid = RandomizedSearchCV(estimator = model, \n",
    "                              param_distributions = param_grid,\n",
    "                              cv = cv, \n",
    "                              verbose = verbose, \n",
    "                              n_iter = n_iter)\n",
    "    \n",
    "    # Fit Selected Model with Random Parameters\n",
    "    grid_result = grid.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predict Y values\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    # Generate Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1)) / len(Y_pred)\n",
    "\n",
    "    # Calculate Label Accuracy\n",
    "    label_acc = cal_label_accuracy(conf_matrix, verbose  = 1)\n",
    "\n",
    "#     with open(output_file, 'a') as f:\n",
    "\n",
    "#         s = ('Running {} data set\\nBest Accuracy : '\n",
    "#              '{:.4f}\\n{}\\nTest Accuracy : {:.4f}\\n\\n')\n",
    "\n",
    "#         output_string = s.format(\n",
    "#                             source,\n",
    "#                             grid_result.best_score_,\n",
    "#                             grid_result.best_params_,\n",
    "#                             label_acc)\n",
    "\n",
    "#         print(output_string)\n",
    "\n",
    "#         f.write(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "sent_tokenizer = False\n",
    "\n",
    "use_nltk_cleaning = False\n",
    "\n",
    "use_tfidf_tokenizer = False # TODO: Adjust for input to CNN\n",
    "use_keras_tokenizer = True\n",
    "\n",
    "use_pretrained_embeddings = True\n",
    "use_tfidf_as_embedding_weights = True\n",
    "\n",
    "\n",
    "data = {}\n",
    "\n",
    "# Initialize Model\n",
    "data['epochs'] = 30\n",
    "data['batch_size'] = 16\n",
    "data['output_label'] = len(np.unique(encoded_Y))\n",
    "data['num_words'] = 5000\n",
    "data['cv'] = 4\n",
    "data['n_iter'] = 5\n",
    "data['Y_train'] = Y_train\n",
    "data['Y_test'] = Y_test\n",
    "data['seq_input_len'] = 50\n",
    "data['embedding_dim'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre = data_preprocessing(sentences_train = sentences_train, \n",
    "                       sentences_test = sentences_test, \n",
    "                       num_words = num_words, \n",
    "                       seq_input_len = seq_input_len, \n",
    "                       filepath = filepath,\n",
    "                       use_keras_tokenizer = True, \n",
    "                       use_tfidf_tokenizer = False, \n",
    "                       use_tfidf_as_embedding_weights = True,\n",
    "                       use_pretrained_embeddings = False)\n",
    "\n",
    "# Concat two dictionaries\n",
    "data = {**data, **data_pre}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epochs', 'batch_size', 'output_label', 'num_words', 'cv', 'n_iter', 'Y_train', 'Y_test', 'seq_input_len', 'embedding_dim', 'X_train', 'X_test', 'vocab_size', 'vocab', 'embedding_matrix'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2916"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer weight shape (3000, 50) not compatible with provided weight shape (2916, 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-38eb9851742e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m                             \u001b[0moutput_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'output_label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                             \u001b[0mvocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vocab_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                             verbose = 1)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-72-ebdf9c4b53b7>\u001b[0m in \u001b[0;36mhyperparameter_optimization\u001b[1;34m(create_model, X_train, Y_train, X_test, Y_test, epochs, batch_size, param_grid, cv, n_iter, embedding_dim, seq_input_len, output_label, vocab_size, verbose)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# Fit Selected Model with Random Parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Predict Y values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid shape for y: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m           **self.filter_sk_params(self.build_fn.__call__))\n\u001b[0;32m    156\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     if (losses.is_categorical_crossentropy(self.model.loss) and\n",
      "\u001b[1;32m<ipython-input-58-d4314abb5eae>\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(num_filters_cv, kernel_size_cv, vocab_size, embedding_dim, seq_input_len, output_label)\u001b[0m\n\u001b[0;32m     12\u001b[0m                                    \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                                    \u001b[0minput_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq_input_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                                    trainable = False))\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    206\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m--> 952\u001b[1;33m                                                 input_list)\n\u001b[0m\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[1;32m-> 1091\u001b[1;33m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    860\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2720\u001b[0m           \u001b[1;31m# Using `init_scope` since we want variable assignment in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2721\u001b[0m           \u001b[1;31m# `set_weights` to be treated like variable initialization.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2722\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2723\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2724\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1871\u001b[0m           raise ValueError(\n\u001b[0;32m   1872\u001b[0m               \u001b[1;34m'Layer weight shape %s not compatible with provided weight '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1873\u001b[1;33m               'shape %s' % (ref_shape, weight.shape))\n\u001b[0m\u001b[0;32m   1874\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1875\u001b[0m         \u001b[0mweight_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer weight shape (3000, 50) not compatible with provided weight shape (2916, 50)"
     ]
    }
   ],
   "source": [
    "hyperparameter_optimization(create_model, \n",
    "                            X_train = data['X_train'], \n",
    "                            Y_train = Y_train, \n",
    "                            X_test = data['X_test'], \n",
    "                            Y_test = data['Y_test'] , \n",
    "                            epochs = data['epochs'] , \n",
    "                            batch_size = data['batch_size'], \n",
    "                            param_grid = param_grid, \n",
    "                            cv = data['cv'], \n",
    "                            n_iter = data['n_iter'],\n",
    "                            embedding_dim  = data['embedding_dim'], \n",
    "                            seq_input_len = data['seq_input_len'], \n",
    "                            output_label = data['output_label'],\n",
    "                            vocab_size = data['vocab_size'],\n",
    "                            verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
