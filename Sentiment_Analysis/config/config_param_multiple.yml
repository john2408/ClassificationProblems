params : 
  model:
    running_CNN: True
    running_SVM: True
    seed : 123
  input_data : 
    data : "data/ML_data_2.0.xlsx"
    sep : ',' # CSV separator
    read_type : 'excel' # it can be 'csv' or 'excel'

  tokenization_options:
    sent_tokenizer : False # TODO: Adjust for input to CNN

    # Text Cleaning Options
    use_nltk_cleaning : True
    text_cleaning : False

    # Word Tokenizer Options
    use_tfidf_tokenizer : True # Not ready to use for CNN , more suitable for CNN, can also 
    use_keras_tokenizer : False # More suitable for SVM, or Naive Bayes

    # If set to FALSE then keras embedding space training is used instead
    # Embedding Space possibilites are GloVe or TFIDF
    use_pretrained_embeddings : True

    # Only if use_pretrained_embeddings == True then select embedding vector space type
    use_glove_pretrained_embeddings_weights : False
    use_tfidf_as_embedding_weights : True
  
    imbalanced_classes : True # parameter for SVM

    make_all_other_classes_1 : False
    remove_class_0 : True

  data: 
    # Initialize Model
    epochs : 30 # NO. of optimizatoin runs
    batch_size : 16 # No. of sentences batch to train
    num_words : 5000 # No. of words to use in the embedding space of GloVe or TFIDF
    cv : 4 # No. of Cross Validations
    n_iter : 5 # No. of Iterations
    seq_input_len : 40 # Length of the vector sentence ( no. of words per sentence)
    embedding_dim : 40 # Length of the word vector ( dimension in the embedding space)
    nodes_hidden_dense_layer : 5 # No. of nodes for hidden Dense layer
    filepath : 'D:/Semillero Data Science/Deep Learning/pre-trained Word Embeddings/GloVe/glove.6B.50d.txt' # File path to GLoVe pretrained embedding word
    
    SVM:
      C : 1.0
      kernel : 'linear'
      degree : 3
      gamma : 'auto'
      class_weights:
        '0': 0.05
        '1': 1
        '2': 1
        '3': 1
        '4': 1
      class_weights_2:
        '0': 0.7
        '1': 1
      class_weights_1_2_3_4:
        '0': 1
        '1': 1
        '2': 1
        '3': 1



  hyperparam:
    num_filters_cv: # No of filter to use in convolution
      - [64,16] 
      - [64,32] 
      - [128,16] 
      - [128,32] 
      - [256,64]
      - [256,32]
      - [256,64]
      - [512,128]
      - [512, 32]
            
    kernel_size_cv:  # No of words to check per Convolution
      - [2,3]
      - [2,4]
      - [3,4]
      - [3,5]  
    vocab_size: # Vocab size if keras embedding space training is wanted
      - 3000
      - 4000
      - 5000
      - 6000 

    embedding_dim:
      - 20 
      - 30
      - 40
      - 50
    seq_input_len:
      - 50
      - 40
      - 30
      - 20
      - 10 

    nodes_hidden_dense_layer : [5, 10, 15, 20, 40]
    use_pretrained_embeddings : [True, False]